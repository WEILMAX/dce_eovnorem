{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from src.models.metrics import calculate_aic_bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'nw2'\n",
    "turbine = 'c02'\n",
    "mode = 'SS2'\n",
    "\n",
    "# GET THE DATA\n",
    "package_folder = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "data_folder = os.path.join(package_folder, 'data')\n",
    "models_folder = os.path.join(package_folder, 'models')\n",
    "ss2_selected = pd.read_csv(os.path.join(data_folder, 'processed','nw2', turbine+'_ss2_selected_data_large.csv'))\n",
    "ss2_selected['timestamp'] = pd.to_datetime(ss2_selected['timestamp'])\n",
    "ss2_selected.set_index('timestamp', inplace=True)\n",
    "\n",
    "SS1_dbscan = pd.read_parquet(os.path.join(data_folder, 'interim',loc,'tracked_modes', 'dbscan_based', loc+turbine+'_SS1_mode.parquet'))\n",
    "SS2_dbscan = pd.read_parquet(os.path.join(data_folder, 'interim',loc,'tracked_modes', 'dbscan_based', loc+turbine+'_SS2_mode.parquet'))\n",
    "FA1_dbscan = pd.read_parquet(os.path.join(data_folder, 'interim',loc,'tracked_modes', 'dbscan_based', loc+turbine+'_FA1_mode.parquet'))\n",
    "FA2_dbscan = pd.read_parquet(os.path.join(data_folder, 'interim',loc,'tracked_modes', 'dbscan_based', loc+turbine+'_FA2_mode.parquet'))\n",
    "\n",
    "rfe_selected_data = pd.read_parquet(os.path.join(data_folder, 'interim', loc, 'rfe_selected_data', loc+turbine+'_rfe_selected_data.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 1.0355808857258562, MSE: 0.00020077205778828714, R2: -0.0011423574298663475\n"
     ]
    }
   ],
   "source": [
    "##Prepare the training and test data\n",
    "\n",
    "#choose y_ to be SS1_dbscan but uniquely indexed keeping the index with hghest value in size column when duplicated\n",
    "y_ = ss2_selected.copy()\n",
    "y_ = y_.sort_values(by=['size'], ascending=False)\n",
    "y_ = y_.loc[~y_.index.duplicated(keep='last')]\n",
    "y_ = y_.sort_index()\n",
    "\n",
    "#Synchronize data\n",
    "Xy = pd.DataFrame(y_['mean_frequency'])\n",
    "for col in rfe_selected_data.columns:\n",
    "    Xy[col] = rfe_selected_data[col]\n",
    "Xy.dropna(inplace=True)\n",
    "y = Xy.iloc[:,0]\n",
    "X_ = Xy[rfe_selected_data.columns]\n",
    "\n",
    "#preprocess the data\n",
    "from src.data.preprocessing import sin_cos_angle_inputs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = sin_cos_angle_inputs(X_)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "# MinMaxnormalization of the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mean = y_train.mean()\n",
    "mse = mean_squared_error(y_test, [mean]*len(y_test))\n",
    "r2 = r2_score(y_test, [mean]*len(y_test))\n",
    "print(f'Mean: {mean}, MSE: {mse}, R2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.21912574448306682, MSE: 9.147559528369654e-06, R2: -3.7997905095954465e-05\n"
     ]
    }
   ],
   "source": [
    "##Prepare the training and test data\n",
    "\n",
    "#choose y_ to be SS1_dbscan but uniquely indexed keeping the index with hghest value in size column when duplicated\n",
    "y_ = SS1_dbscan.copy()\n",
    "y_ = y_.sort_values(by=['size'], ascending=False)\n",
    "y_ = y_.loc[~y_.index.duplicated(keep='last')]\n",
    "y_ = y_.sort_index()\n",
    "\n",
    "#Synchronize data\n",
    "Xy = pd.DataFrame(y_['mean_frequency'])\n",
    "for col in rfe_selected_data.columns:\n",
    "    Xy[col] = rfe_selected_data[col]\n",
    "Xy.dropna(inplace=True)\n",
    "y = Xy.iloc[:,0]\n",
    "X_ = Xy[rfe_selected_data.columns]\n",
    "\n",
    "#preprocess the data\n",
    "from src.data.preprocessing import sin_cos_angle_inputs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = sin_cos_angle_inputs(X_)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "# MinMaxnormalization of the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mean = y_train.mean()\n",
    "mse = mean_squared_error(y_test, [mean]*len(y_test))\n",
    "r2 = r2_score(y_test, [mean]*len(y_test))\n",
    "print(f'Mean: {mean}, MSE: {mse}, R2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.21958441198426598, MSE: 6.04736317478754e-05, R2: -0.0005598517765166289\n"
     ]
    }
   ],
   "source": [
    "##Prepare the training and test data\n",
    "\n",
    "#choose y_ to be SS1_dbscan but uniquely indexed keeping the index with hghest value in size column when duplicated\n",
    "y_ = FA1_dbscan.copy()\n",
    "y_ = y_.sort_values(by=['size'], ascending=False)\n",
    "y_ = y_.loc[~y_.index.duplicated(keep='last')]\n",
    "y_ = y_.sort_index()\n",
    "\n",
    "#Synchronize data\n",
    "Xy = pd.DataFrame(y_['mean_frequency'])\n",
    "for col in rfe_selected_data.columns:\n",
    "    Xy[col] = rfe_selected_data[col]\n",
    "Xy.dropna(inplace=True)\n",
    "y = Xy.iloc[:,0]\n",
    "X_ = Xy[rfe_selected_data.columns]\n",
    "\n",
    "#preprocess the data\n",
    "from src.data.preprocessing import sin_cos_angle_inputs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = sin_cos_angle_inputs(X_)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "# MinMaxnormalization of the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mean = y_train.mean()\n",
    "mse = mean_squared_error(y_test, [mean]*len(y_test))\n",
    "r2 = r2_score(y_test, [mean]*len(y_test))\n",
    "print(f'Mean: {mean}, MSE: {mse}, R2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dce_eov_norm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
